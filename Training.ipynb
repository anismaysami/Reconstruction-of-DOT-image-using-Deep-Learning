{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anismaysami/Reconstruction-of-DOT-image-using-Deep-Learning/blob/main/NeuralNetArchitecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reconstruction-of-DOT-image-using-Deep-Learning\n",
        "This program tests various artificial neural networks to reconstruct Diffuse optical tomography Images. Here, we proposed 5 models include:\n",
        "\n",
        "1.   MLP model as a fully connected neural networks\n",
        "2.   DOT_conv model as a convolutional NN\n",
        "3.   Single_layer model as a single fully connected layer (to observe the effect of NN in reconstructing of DOT images\n",
        "4.   Dense_conv model  a combination model of Dense and Convolutional layers\n",
        "5.   cnn2 model as another convolution architecture\n",
        "\n",
        "The performance of networks was evaluated by 4 metrics including mean absolute error (MAE), mean squared error (MSE), Peak Signal to Noise Ratio (PSNR), and Structural Similarity Index Metric (SSIM). For comparison with model-based DOT reconstruction methods, we used the Conjugate gradient algorithm with Total variation (TV) regularization. Fig.1 shows ground truth and reconstructed distribution of absorption coefficient in z=25. Result shows, by using fully connected layer and convolutional neural network, MAE 76% and 69% and MSE 84% and 62% respectively were reduced and PSNR was doubled in comparison with CG. Accordingly, both neural networks have better performance in DOT image reconstruction than model-based method.\n",
        "\n"
      ],
      "metadata": {
        "id": "Rnp2dOkrC7EQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqEGuxkUdXbB"
      },
      "source": [
        "#Importing needed packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKxidgcYdUOJ"
      },
      "outputs": [],
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb2vS9YAJ7Rn"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/MyDrive/*.py\n",
        "!cat '/content/drive/MyDrive/evaluate_metrics.py'\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Epe85KSqdvel"
      },
      "outputs": [],
      "source": [
        "#importing packages needed\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_absolute_error as MAE\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "#from evaluate_metrics import PSNR, SSIM\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow.keras.backend as K\n",
        "from superscript import get super\n",
        "%run -i superscript.py\n",
        "%matplotlib inline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFhfSusGTyN1"
      },
      "outputs": [],
      "source": [
        "def scheduler(epoch, lr):\n",
        "   if epoch < 10:\n",
        "     return lr\n",
        "   else:\n",
        "     return lr*math.exp(-0.1)\n",
        "   #if epoch <30:\n",
        "      #return 0.0005\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VljGMQetVNwZ"
      },
      "outputs": [],
      "source": [
        "LS=tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZ0Rpt7IyV1n"
      },
      "source": [
        "#Importing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMURxAlKdx1m"
      },
      "outputs": [],
      "source": [
        "#importing data\n",
        "hf_data=h5py.File('/content/drive/MyDrive/data.h5', 'r')\n",
        "data = hf_data['data'][...]\n",
        "hf_data.close()\n",
        "hf_mua=h5py.File('/content/drive/MyDrive/mua.h5', 'r')\n",
        "mua = hf_mua['mua'][...]\n",
        "hf_mua.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFBO0uErdTAm"
      },
      "outputs": [],
      "source": [
        "# prepare the cross-validation procedure\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTFNjoQcd0NI"
      },
      "outputs": [],
      "source": [
        "#splitting dataset into train,val and test for NOT proccessed dataset\n",
        "seed=7\n",
        "np.random.seed(seed)\n",
        "data_train, data_test, mua_train, mua_test = train_test_split(data, mua, test_size=0.1, random_state=seed)\n",
        "data_train, data_val, mua_train, mua_val = train_test_split(data_train, mua_train, test_size=0.05, random_state=seed)\n",
        "\n",
        "data_train=data_train.astype('float32'); data_test=data_test.astype('float32'); data_val=data_val.astype('float32')\n",
        "mua_train=mua_train.astype('float32'); mua_test=mua_test.astype('float32'); mua_val=mua_val.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DERYIW70u7T7"
      },
      "outputs": [],
      "source": [
        "print('number of train data is:',len(data_train))\n",
        "print('number of test data is:',len(data_test))\n",
        "print('number of validation data is:',len(data_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKnSgItmBzZ7"
      },
      "outputs": [],
      "source": [
        "def scaled_data(data_train, data_test, data_val, scaler):\n",
        "  data_train=data_train.reshape(data_train.shape[0], data_train.shape[1])\n",
        "  data_test=data_test.reshape(data_test.shape[0], data_test.shape[1])\n",
        "  data_val=data_val.reshape(data_val.shape[0], data_val.shape[1])\n",
        "\n",
        "  scaled_data_train=scaler.fit_transform(data_train)\n",
        "  scaled_data_test=scaler.transform(data_test)\n",
        "  scaled_data_val=scaler.transform(data_val)\n",
        "\n",
        "  # inverse transform\n",
        "  inverse_data_train = scaler.inverse_transform(scaled_data_train)\n",
        "  inverse_data_test = scaler.inverse_transform(scaled_data_test)\n",
        "  inverse_data_val = scaler.inverse_transform(scaled_data_val)\n",
        "  return scaled_data_train, scaled_data_test, scaled_data_val, inverse_data_train, inverse_data_test, scaled_data_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JP39PN1z5157"
      },
      "outputs": [],
      "source": [
        "#normalize data and test\n",
        "norm_data_scaler=MinMaxScaler(feature_range=(0,1))\n",
        "norm_data_train, norm_data_test, norm_data_val, inverse_ndata_train, inverse_ndata_test, inverse_ndata_val = scaled_data(data_train, data_test, data_val, norm_data_scaler)\n",
        "\n",
        "#standardize data train and test\n",
        "standard_data_scaler=StandardScaler()\n",
        "standard_data_train, standard_data_test, standard_data_val, inverse_sdata_train, inverse_sdata_test, inverse_sdata_val = scaled_data(data_train, data_test, data_val, standard_data_scaler)\n",
        "\n",
        "#normalize mua train and test\n",
        "norm_mua_scaler=MinMaxScaler(feature_range=(0,1))\n",
        "norm_mua_train, norm_mua_test, norm_mua_val, inverse_nmua_train, inverse_nmua_test, inverse_nmua_val = scaled_data(mua_train, mua_test, mua_val, norm_mua_scaler)\n",
        "\n",
        "#standardize mua train and test\n",
        "standard_mua_scaler=StandardScaler()\n",
        "standard_mua_train, standard_mua_test, standard_mua_val, inverse_smua_train, inverse_smua_test, inverse_smua_val = scaled_data(mua_train, mua_test, mua_val, standard_mua_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cn0xZFe6FZAb"
      },
      "outputs": [],
      "source": [
        "#standardizing norm data\n",
        "standard_ndata_scaler=StandardScaler()\n",
        "standard_ndata_train, standard_ndata_test, standard_ndata_val, inverse_sndata_train, inverse_sndata_test, inverse_sndata_val = scaled_data(norm_data_train, norm_data_test, norm_data_val, standard_ndata_scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Rw_VScNol4y"
      },
      "outputs": [],
      "source": [
        "EL=EarlyStopping(monitor='val_loss', min_delta=1e-9, patience=5, mode='auto')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing models and Evaluate matrics"
      ],
      "metadata": {
        "id": "RWVL9PogoBvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from DOTModels import MLP_model, DOT_convnet, Single_layer, dense_conv, cnn_2\n",
        "from metrics import MAE, MSE, PSNR, SSIM\n",
        "%run -i DOTModels.py\n",
        "%run -i metrics.py"
      ],
      "metadata": {
        "id": "UKA12XwfoNs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train, Test, Evaluation dataset for prepared model"
      ],
      "metadata": {
        "id": "56CeHf1h_kn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize data (input) train, test, val for mlp_model, single_layer, Dense_conv\n",
        "norm_data_train=norm_data_train.reshape(len(norm_data_train), 625, 1)\n",
        "norm_data_test=norm_data_test.reshape(len(norm_data_test), 625, 1)\n",
        "norm_data_val=norm_data_val.reshape(len(norm_data_val), 625, 1)\n",
        "\n",
        "#Normalize data (input) train, test, val for DOT_convnet and cnn2\n",
        "norm_data_train_conv=norm_data_train.reshape(len(norm_data_train), 25, 25, 1)\n",
        "norm_data_test_conv=norm_data_test.reshape(len(norm_data_test), 25, 25, 1)\n",
        "\n",
        "#Normalize mua (label) train, test, val for mlp_model, DOT_convnet, Single_layer, cnn2\n",
        "mua_train=mua_train.reshape(len(mua_train), 4096,1)\n",
        "mua_test=mua_test.reshape(len(mua_test), 4096, 1)\n",
        "mua_val=mua_val.reshape(len(mua_val), 4096, 1)"
      ],
      "metadata": {
        "id": "UokNjeWQ_upa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpdVzexWy09c"
      },
      "source": [
        "#MLP_model (FCNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting MLP_model**"
      ],
      "metadata": {
        "id": "_n090My5HfZ5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMH0AuIVaSZs"
      },
      "outputs": [],
      "source": [
        "model_1=MLP_model()\n",
        "history=model_1.fit(norm_data_train, mua_train, epochs=1000, batch_size=128, validation_data=(norm_data_val, mua_val), callbacks=[EL])#,LS])\n",
        "#round(model.optimizer.lr.numpy(), 5)\n",
        "test_loss=model_1.evaluate(norm_data_test, mua_test, steps=10)\n",
        "plt.plot(history.history['mean_absolute_error'])\n",
        "plt.plot(history.history['val_mean_absolute_error'])\n",
        "plt.show()\n",
        "#plot learning curves\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.title('learning curve of MLP_model', pad=-50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict by MLP_model**"
      ],
      "metadata": {
        "id": "H1dQtPVuA8i7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC5tx98aVX4n"
      },
      "outputs": [],
      "source": [
        "mua_MLP_hat=model_1.predict(norm_data_test) # mua_MLP_hat is predicted mua by MLP_model\n",
        "index=105\n",
        "\n",
        "#display predicted by MLP_model\n",
        "plt.imshow(mua_MLP_hat[105].reshape(64,64))\n",
        "plt.title('Prediction by MLP_model')\n",
        "plt.colorbar()\n",
        "\n",
        "#displays ground truth\n",
        "plt.imshow(mua_test[index].reshape(64,64))\n",
        "plt.title('Ground truth compared to MLP model - \\u03BCa=0.08 mm{}'.format(get_super(\"-1\")))\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate MLP_model**"
      ],
      "metadata": {
        "id": "1zxfmVpQGxEG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK9sBV__wLm2"
      },
      "outputs": [],
      "source": [
        "index=100\n",
        "y_test=mua_test[index].reshape(64,64) # y_test is mua_test\n",
        "y_mlp_pred=mua_MLP_hat[index].reshape(64,64) #y_mlp_pred is predicted mua by mlp\n",
        "mae_mlp=MAE(y_test, y_mlp_pred)\n",
        "mse_mlp=MSE(y_test, y_mlp_pred)\n",
        "psnr_mlp=PSNR(y_test, y_mlp_pred)\n",
        "print('Mean Absolute Error:', mae_mlp)\n",
        "print('Mean Squared Error:', mse_mlp)\n",
        "print('Peak Signal to Noise Ratio:', psnr_mlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving MLP_model as mlp_model.h5**"
      ],
      "metadata": {
        "id": "FxfCOH2FHnNC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STi8wNhxN0Uv"
      },
      "outputs": [],
      "source": [
        "##save model_1 (model_1 is fcnn)\n",
        "model_1.save('/content/drive/MyDrive/mlp_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOdKc2mEzgHx"
      },
      "source": [
        "#DOT_convnet (Convolutional neural  network)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting DOT_convnet model**"
      ],
      "metadata": {
        "id": "j62fECpeRUr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2=DOT_convnet()\n",
        "history=model_2.fit(norm_data_train_conv, mua_train, epochs=1000, batch_size=128, validation_data=(norm_data_test, mua_test), callbacks=[EL])\n",
        "test_loss=model_2.evaluate(norm_data_test_conv, mua_test, steps=10)\n",
        "#plot learning curves\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.title('learning curve of DOT_convnet model', pad=-50)"
      ],
      "metadata": {
        "id": "SAw_yTouMg7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict by DOT_convnet model**"
      ],
      "metadata": {
        "id": "vMVUUZ4PRTxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mua_DOT_convnet_hat=model_2.predict(norm_data_test_conv) # mua_DOT_convnet_hat is predicted mua by DOT_convnet_model\n",
        "index=16\n",
        "\n",
        "#display predicted by DOT_convnet model\n",
        "plt.imshow(mua_DOT_convnet_hat[index].reshape(64,64))\n",
        "plt.title('Prediction')\n",
        "plt.colorbar()\n",
        "\n",
        "#displays ground truth\n",
        "plt.imshow(mua_test[index].reshape(64,64))\n",
        "plt.title('Ground truth - \\u03BCa=0.08 mm{}'.format(get_super('-1')))\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "FKcYf8LkXtp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate DOT_convnet model**"
      ],
      "metadata": {
        "id": "QnHiJm2HYzqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index=100\n",
        "y_test=mua_test[index].reshape(64,64) # y_test is mua_test\n",
        "y_dot_convnet_pred=mua_DOT_convnet_hat[index].reshape(64,64) # y_dot_convnet_pred is predicted mua by dot_convnet model\n",
        "mae_dot_convnet=MAE(y_test, y_dot_convnet_pred)\n",
        "mse_dot_convnet=MSE(y_test, y_dot_convnet_pred)\n",
        "psnr_dot_convnet=PSNR(y_test, y_dot_convnet_pred)\n",
        "print('Mean Absolute Error:', mae_dot_convnet)\n",
        "print('Mean Squared Error:', msedot_convnet)\n",
        "print('Peak Signal to Noise Ratio:', psnrdot_convnet)"
      ],
      "metadata": {
        "id": "pOVro80XS5_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving DOT_convnet as DOT_convnet_model.h5**"
      ],
      "metadata": {
        "id": "bk4vUuV5Zmiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#save model_2 (model_2 is DOT_convnet)\n",
        "model_2.save('/content/drive/MyDrive/DOT_convnet_model.h5')"
      ],
      "metadata": {
        "id": "iDyOaIIGjYJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDj0mXpeEkxL"
      },
      "source": [
        "#Single_layer (Fully connected layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting Single_layer model**"
      ],
      "metadata": {
        "id": "LPiORbg0kr7u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBwmR4eoEj5I"
      },
      "outputs": [],
      "source": [
        "model_3=Single_layer()\n",
        "history=model_3.fit(norm_data_train, mua_train, epochs=1000, batch_size=128, validation_data=(norm_data_val, mua_val), callbacks=[EL])#,LS])\n",
        "#round(model.optimizer.lr.numpy(), 5)\n",
        "test_loss=model_3.evaluate(norm_data_test, mua_test, steps=10)\n",
        "plt.plot(history.history['mean_absolute_error'])\n",
        "plt.plot(history.history['val_mean_absolute_error'])\n",
        "plt.show()\n",
        "#plot learning curves\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.title('learning curve of single layer model', pad=-50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict by Single_layer model**"
      ],
      "metadata": {
        "id": "gbWlQJUqlIRy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qul58a4I8LB"
      },
      "outputs": [],
      "source": [
        "mua_single_layer_hat=model.predict(norm_data_test) # mua_single_layer_hat is predicted mua by single_layer model\n",
        "index=0\n",
        "\n",
        "#display predicted by single layer model\n",
        "plt.imshow(mua_single_layer_hat[index].reshape(64,64))\n",
        "plt.title('Prediction by single layer model')\n",
        "plt.colorbar()\n",
        "\n",
        "#displays ground truth\n",
        "plt.imshow(mua_test[index].reshape(64,64))\n",
        "plt.title('Ground truth compared to single_layer model - \\u03BCa=0.08 mm{}'.format(get_super(\"-1\")))\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Single_layer model**"
      ],
      "metadata": {
        "id": "cSkQuLHcsznX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNXyhsVtbcRQ"
      },
      "outputs": [],
      "source": [
        "index=255\n",
        "y_test=mua_test[index].reshape(64,64) #y_test is mua_test\n",
        "y_single_layer_pred=mua_single_layer_hat[index].reshape(64,64) # y_single_layer_pred is predicted mua by single_layer\n",
        "mae_single_layer=MAE(y_test, y_single_layer_pred)\n",
        "mse_single_layer=MSE(y_test, y_single_layer_pred)\n",
        "psnr_single_layer=PSNR(y_test, y_single_layer_pred)\n",
        "print('Mean Absolute Error:', mae_single_layer)\n",
        "print('Mean Squared Error:', mse_single_layer)\n",
        "print('Peak Signal to Noise Ratio:', psnr_single_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving Single_layer model as Single_layer_model.h5**"
      ],
      "metadata": {
        "id": "z4mU38GsukCS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBXeRj4jRniY"
      },
      "outputs": [],
      "source": [
        "model_3.save('/content/drive/MyDrive/Single_layer_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dense_conv model"
      ],
      "metadata": {
        "id": "h6iugtosvr96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fitting Dense_conv model**"
      ],
      "metadata": {
        "id": "MMD6jvgBw6U5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YiY5-5SobSf"
      },
      "outputs": [],
      "source": [
        "model_4=dense_conv()\n",
        "history=model_4.fit(norm_data_train, mua_train, epochs=500, batch_size=128, validation_data=(norm_data_val, mua_val), callbacks=[EL])#,LS])\n",
        "#round(model.optimizer.lr.numpy(), 5)\n",
        "test_loss=model_4.evaluate(norm_data_test, mua_test, steps=10)\n",
        "\n",
        "#plot learning curves\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.title('learning curve of Dense_conv', pad=-50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict by Dense_conv model**"
      ],
      "metadata": {
        "id": "HFgY3FnY18dw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcrSi7YdfsoZ"
      },
      "outputs": [],
      "source": [
        "mua_Dense_conv_hat=model_4.predict(norm_data_test) # mua_Dense_conv_hat is predicted mua by Dense_conv model\n",
        "index=9\n",
        "\n",
        "#display predicted by dense model\n",
        "plt.imshow(mua_Dense_conv_hat[index].reshape(64,64))\n",
        "plt.title('Prediction by Dense_conv model')\n",
        "plt.colorbar()\n",
        "\n",
        "#displays ground truth\n",
        "plt.imshow(mua_test[index].reshape(64,64))\n",
        "plt.title('Ground truth compared to Dense_conv model - \\u03BCa=0.08 mm{}'.format(get_super(\"-1\")))\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate Dense_conv model**"
      ],
      "metadata": {
        "id": "AkXwtONJ5PJX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4Cr5CTzfyok"
      },
      "outputs": [],
      "source": [
        "index=255\n",
        "y_test=mua_test[index].reshape(64,64) #y_test is mua_test\n",
        "y_Dense_conv_pred=mua_Dense_conv_hat[index].reshape(64,64) # y_Dense_conv_pred is  predicted mua by Dense_conv model\n",
        "mae_Dense_conv=MAE(y_test, y_Dense_conv_pred)\n",
        "mse_Dense_conv=MSE(y_test, y_Dense_conv_pred)\n",
        "psnr_Dense_conv=PSNR(y_test, y_Dense_conv_pred)\n",
        "print('Mean Absolute Error:', mae_Dense_conv)\n",
        "print('Mean Squared Error:', mse_Dense_conv)\n",
        "print('Peak Signal to Noise Ratio:', psnr_Dense_conv)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving Dense_conv model as Dense_conv_model.h5**"
      ],
      "metadata": {
        "id": "w1LDFX6L704P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.save('/content/drive/MyDrive/Dense_conv_model.h5')"
      ],
      "metadata": {
        "id": "JnNagGbD8wu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGmSkDCPkVII"
      },
      "source": [
        "#cnn2 model (Convolutional neural network)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Fitting cnn2 model**"
      ],
      "metadata": {
        "id": "Y7ka0bP8_GN4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0-dzsMREaIx"
      },
      "outputs": [],
      "source": [
        "model_5=cnn_2()\n",
        "history=model_5.fit(norm_data_train_conv, mua_train, epochs=1000, batch_size=128, validation_data=(norm_data_test_conv, mua_test),shuffle=True, callbacks=[EL])\n",
        "test_loss=model_5.evaluate(norm_data_test_conv, mua_test, steps=10)\n",
        "plt.plot(history.history['mean_absolute_error'])\n",
        "plt.plot(history.history['val_mean_absolute_error'])\n",
        "plt.show()\n",
        "#plot learning curves\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.title('learning curve of cnn2 model', pad=-50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predict by cnn2 model**"
      ],
      "metadata": {
        "id": "LEuiTuHtBQ6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mua_cnn2_hat=model_4.predict(norm_data_test_conv) # mua_cnn2_hat is predicted mua by cnn2 model\n",
        "index=9\n",
        "\n",
        "#display predicted by cnn2 model\n",
        "plt.imshow(mua_cnn2_hat[index].reshape(64,64))\n",
        "plt.title('Prediction by cnn2 model')\n",
        "plt.colorbar()\n",
        "\n",
        "#displays ground truth\n",
        "plt.imshow(mua_test[index].reshape(64,64))\n",
        "plt.title('Ground truth compared to cnn2 model - \\u03BCa=0.08 mm{}'.format(geT_super(\"-1\")))\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "CSaslQzLBaVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluate cnn2 model**"
      ],
      "metadata": {
        "id": "s2fKdqQtB-x2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index=255\n",
        "y_test=mua_test[index].reshape(64,64) #y_test is mua_test\n",
        "y_cnn2_pred=mua_cnn2_hat[index].reshape(64,64) # y_cnn2_pred is  predicted mua by cnn2 model\n",
        "mae_cnn2=MAE(y_test, y_cnn2_pred)\n",
        "mse_cnn2=MSE(y_test, y_cnn2_pred)\n",
        "psnr_cnn2=PSNR(y_test, y_cnn2_pred)\n",
        "print('Mean Absolute Error:', mae_cnn2)\n",
        "print('Mean Squared Error:', mse_cnn2)\n",
        "print('Peak Signal to Noise Ratio:', psnr_cnn2)"
      ],
      "metadata": {
        "id": "z1eFu3tiCI1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving cnn2 model as cnn2_model.h5**"
      ],
      "metadata": {
        "id": "z8Fyalh0Ck_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.save('/content/drive/MyDrive/cnn2_model.h5')"
      ],
      "metadata": {
        "id": "f3MjU9JgCtxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading models"
      ],
      "metadata": {
        "id": "PMu14wQVF5s3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing needed package**"
      ],
      "metadata": {
        "id": "D23bnBK8GCmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model"
      ],
      "metadata": {
        "id": "sD0HEysoF-Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading MLP model**"
      ],
      "metadata": {
        "id": "Z780mf6dG-W9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load MLp_model\n",
        "model_1 = load_model('/content/drive/MyDrive/mlp_model.h5')\n",
        "#summarize model.\n",
        "model_1.summary()"
      ],
      "metadata": {
        "id": "Jw7ZZ2bVGtwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading DOT_conv model**"
      ],
      "metadata": {
        "id": "9X8W9zG5HCj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load DOT_conv model\n",
        "model_2 = load_model('/content/drive/MyDrive/DOT_convnet_model.h5')\n",
        "#summarize model.\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "sKVCKa_JHM4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Single layer model**"
      ],
      "metadata": {
        "id": "1d6tcaVyIHAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load Single_layer model\n",
        "model_3 = load_model('/content/drive/MyDrive/Single_layer_model.h5')\n",
        "#summarize model.\n",
        "model_3.summary()"
      ],
      "metadata": {
        "id": "cTwJ-qKnIWmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Dense_conv model**"
      ],
      "metadata": {
        "id": "uVSVc1tWIplQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = load_model('/content/drive/MyDrive/Dense_conv_model.h5')\n",
        "#summarize model.\n",
        "model_4.summary()"
      ],
      "metadata": {
        "id": "hc-zz5v_IwlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading cnn2  model**"
      ],
      "metadata": {
        "id": "3iJLRQZ6I8ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_5 = load_model('/content/drive/MyDrive/cnn2_model.h5')\n",
        "#summarize model.\n",
        "model_5.summary()"
      ],
      "metadata": {
        "id": "pmBjjF0cJB6I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "zqEGuxkUdXbB",
        "RZ0Rpt7IyV1n",
        "RWVL9PogoBvo",
        "56CeHf1h_kn4",
        "tpdVzexWy09c",
        "tOdKc2mEzgHx",
        "eDj0mXpeEkxL",
        "h6iugtosvr96",
        "UGmSkDCPkVII",
        "PMu14wQVF5s3"
      ],
      "provenance": [],
      "mount_file_id": "1X8IBnmWy7Kn3iAEUtjarXT95HjNtAzwj",
      "authorship_tag": "ABX9TyNR/O9sxf8mDlaemt7zaokC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
